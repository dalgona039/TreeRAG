import json
import os
from typing import Any, List, Dict, Optional, Literal
from src.config import Config
from src.core.tree_traversal import TreeNavigator, format_traversal_results
from src.core.beam_search import BeamSearchNavigator, format_beam_results
from src.core.contextual_compressor import ContextualCompressor, format_compressed_context
from src.core.reference_resolver import ReferenceResolver
from src.utils.cache import get_cache
from src.utils.hallucination_detector import create_detector

# Traversal algorithm types
TraversalAlgorithm = Literal["dfs", "beam_search"]

DOMAIN_PROMPTS = {
    "general": """ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì œê³µëœ ë¬¸ì„œì˜ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.""",
    
    "medical": """ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
**ì˜ë£Œ ë¬¸ì„œ ë¶„ì„ ì›ì¹™:**
- ì˜í•™ ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ê³  í•„ìš”ì‹œ ì„¤ëª…ì„ ì¶”ê°€í•˜ì„¸ìš”
- ì„ìƒ ê°€ì´ë“œë¼ì¸ê³¼ ê·¼ê±° ê¸°ë°˜ ì˜í•™(EBM)ì„ ì¤€ìˆ˜í•˜ì„¸ìš”
- ì§„ë‹¨, ì¹˜ë£Œ, ì•½ë¬¼ì— ëŒ€í•œ ì •ë³´ëŠ” ë°˜ë“œì‹œ í˜ì´ì§€ ì°¸ì¡°ì™€ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”
- ë¶€ì‘ìš©, ê¸ˆê¸°ì‚¬í•­, ì£¼ì˜ì‚¬í•­ì„ ëª…í™•íˆ ëª…ì‹œí•˜ì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” "ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”""",
    
    "legal": """ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
**ë²•ë¥  ë¬¸ì„œ ë¶„ì„ ì›ì¹™:**
- ë²•ì¡°ë¬¸ê³¼ ì¡°í•­ì„ ì •í™•íˆ ì¸ìš©í•˜ê³  í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- ì¡°ê±´, ì˜ˆì™¸ì‚¬í•­, ë‹¨ì„œì¡°í•­ì„ ë¹ ì§ì—†ì´ í¬í•¨í•˜ì„¸ìš”
- "~í•  ìˆ˜ ìˆë‹¤", "~í•˜ì—¬ì•¼ í•œë‹¤" ë“±ì˜ ë²•ë¥  ìš©ì–´ë¥¼ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”
- íŒë¡€ë‚˜ ì„ ë¡€ê°€ ì–¸ê¸‰ëœ ê²½ìš° ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”
- ë²•ì  í•´ì„ì´ í•„ìš”í•œ ë¶€ë¶„ì€ ì—¬ëŸ¬ ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”""",
    
    "financial": """ë‹¹ì‹ ì€ ì¬ë¬´/ê¸ˆìœµ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
**ì¬ë¬´ ë¬¸ì„œ ë¶„ì„ ì›ì¹™:**
- ìˆ«ì, ì§€í‘œ, í†µê³„ëŠ” ì ˆëŒ€ì ìœ¼ë¡œ ì •í™•í•´ì•¼ í•˜ë©° ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- ì¬ë¬´ì œí‘œ í•­ëª©(ìì‚°, ë¶€ì±„, ìˆ˜ìµ ë“±)ì„ ì •í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”
- íšŒê³„ ê¸°ì¤€(K-IFRS, GAAP ë“±)ì´ ëª…ì‹œëœ ê²½ìš° ì´ë¥¼ ê³ ë ¤í•˜ì„¸ìš”
- ì „ë…„ ëŒ€ë¹„ ì¦ê°ë¥ , ë¹„ìœ¨ ë“±ì„ ì œì‹œí•  ë•Œ ê³„ì‚° ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ì„¸ìš”
- ë¦¬ìŠ¤í¬ ìš”ì¸, ìš°ë°œì±„ë¬´ ë“± ì£¼ìš” ì¬ë¬´ ìœ„í—˜ì„ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”""",
    
    "academic": """ë‹¹ì‹ ì€ í•™ìˆ  ì—°êµ¬ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
**í•™ìˆ  ë¬¸ì„œ ë¶„ì„ ì›ì¹™:**
- ì—°êµ¬ ë°©ë²•ë¡ , ì‹¤í—˜ ì„¤ê³„, ë°ì´í„° ë¶„ì„ ë°©ë²•ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”
- ì—°êµ¬ ê²°ê³¼ì™€ ì €ìì˜ í•´ì„/ì£¼ì¥ì„ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ì„¸ìš”
- í†µê³„ì  ìœ ì˜ì„±(p-value), ì‹ ë¢°êµ¬ê°„ ë“± ì •ëŸ‰ì  ì§€í‘œë¥¼ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”
- ì„ í–‰ì—°êµ¬ì™€ì˜ ê´€ê³„, ì—°êµ¬ì˜ í•œê³„ì ì„ ëª…ì‹œí•˜ì„¸ìš”
- ì¸ìš© í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ê³  í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”"""
}

LANGUAGE_INSTRUCTIONS = {
    "ko": "**ì¤‘ìš”: ëª¨ë“  ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.**",
    "en": "**IMPORTANT: You MUST respond in English only.**",
    "ja": "**é‡è¦ï¼šå¿…ãšæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚**"
}

class TreeRAGReasoner:
    def __init__(
        self, 
        index_filenames: List[str], 
        use_deep_traversal: bool = True,
        traversal_algorithm: TraversalAlgorithm = "beam_search",
        beam_width: int = 5,
        enable_compression: bool = True
    ):
        self.index_trees: List[Dict[str, Any]] = []
        self.index_filenames = index_filenames
        self.use_deep_traversal = use_deep_traversal
        self.traversal_algorithm = traversal_algorithm
        self.beam_width = beam_width
        self.enable_compression = enable_compression
        self.compressor = ContextualCompressor() if enable_compression else None
        
        for index_filename in index_filenames:
            path = os.path.join(Config.INDEX_DIR, index_filename)
            if not os.path.exists(path):
                raise FileNotFoundError(f"Index file not found: {path}")
            
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    self.index_trees.append(json.load(f))
            except json.JSONDecodeError as e:
                raise ValueError(f"Invalid JSON in index file {index_filename}: {e}")
            except IOError as e:
                raise IOError(f"Failed to read index file {index_filename}: {e}")


    def query(self, user_question: str, enable_comparison: bool = True, max_depth: int = 5, max_branches: int = 3, domain_template: str = "general", language: str = "ko", node_context: Optional[dict] = None) -> tuple[str, dict]:
        if not user_question or not user_question.strip():
            raise ValueError("user_question cannot be empty")
        
        cache = get_cache()
        cached_response = cache.get(
            question=user_question,
            index_files=self.index_filenames,
            use_deep_traversal=self.use_deep_traversal,
            max_depth=max_depth,
            max_branches=max_branches,
            domain_template=domain_template,
            language=language,
            node_context=node_context
        )
        
        if cached_response:
            print(f"âœ… Cache HIT - Returning cached response")
            return cached_response["answer"], cached_response["metadata"]
        
        print(f"âŒ Cache MISS - Generating new response")
        
        traversal_info = {
            "used_deep_traversal": self.use_deep_traversal,
            "nodes_visited": [],
            "nodes_selected": [],
            "max_depth": max_depth,
            "max_branches": max_branches
        }
        
        reference_context = ""
        resolved_refs = []
        for tree in self.index_trees:
            resolver = ReferenceResolver(tree)
            refs = resolver.detect_references(user_question)
            if refs:
                resolved_nodes = resolver.resolve_all_references(user_question)
                if resolved_nodes:
                    resolved_refs.extend(resolved_nodes)
                    ref_context = resolver.format_resolved_context(resolved_nodes)
                    if ref_context:
                        reference_context += ref_context
                        print(f"ğŸ“ Resolved {len(resolved_nodes)} cross-references: {[r.get('title') for r in resolved_nodes]}")
        
        if self.use_deep_traversal:
            print("ğŸŒ² Using deep tree traversal mode")
            context_str, trav_data = self._build_context_with_traversal(user_question, max_depth, max_branches)
            traversal_info.update(trav_data)
        else:
            print("ğŸ“„ Using flat context mode (legacy)")
            context_str = self._build_flat_context()
        
        if reference_context:
            context_str = reference_context + "\n\n" + context_str
        
        is_multi_doc = len(self.index_filenames) > 1
        comparison_prompt = ""
        
        if is_multi_doc and enable_comparison:
            comparison_prompt = f"""

### ğŸ“Š ë‹¤ì¤‘ ë¬¸ì„œ ë¹„êµ ë¶„ì„ (í•„ìˆ˜):
ì—¬ëŸ¬ ë¬¸ì„œê°€ ì œê³µë˜ì—ˆìœ¼ë¯€ë¡œ, ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¹„êµ ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”:

**1. ê³µí†µì  (Commonalities)**
- ëª¨ë“  ë¬¸ì„œì—ì„œ ì¼ì¹˜í•˜ëŠ” ë‚´ìš©
- ì˜ˆ: "ëª¨ë“  êµìœ¡ê³¼ì •ì—ì„œ ì¡¸ì—… í•™ì ì€ 130í•™ì  ì´ìƒ [ë¬¸ì„œA, p.5], [ë¬¸ì„œB, p.3]"

**2. ì°¨ì´ì  (Differences)**
í‘œ í˜•ì‹ìœ¼ë¡œ ëª…í™•íˆ êµ¬ë¶„:
| í•­ëª© | {self.index_filenames[0].replace('_index.json', '')} | {self.index_filenames[1].replace('_index.json', '') if len(self.index_filenames) > 1 else 'ê¸°íƒ€'} |
|------|------|------|
| ì˜ˆ: í•„ìˆ˜í•™ì  | 18í•™ì  [p.5] | 21í•™ì  [p.4] |
| ì˜ˆ: ì„ íƒê³¼ëª© | 10ê°œ [p.7] | 15ê°œ [p.6] |

**3. ë¬¸ì„œ ìš°ì„ ìˆœìœ„ (í•´ë‹¹ì‹œ)**
- ì¶©ëŒí•˜ëŠ” ë‚´ìš©ì´ ìˆë‹¤ë©´, ì–´ë–¤ ë¬¸ì„œê°€ ìµœì‹ /ê³µì‹ì¸ì§€ ëª…ì‹œ
- ì˜ˆ: "ìµœì‹  ë²„ì „(2024)ì˜ ë‚´ìš©ì´ ì ìš©ë©ë‹ˆë‹¤ [ë¬¸ì„œA, p.10]"
"""

        domain_prompt = DOMAIN_PROMPTS.get(domain_template, DOMAIN_PROMPTS["general"])
        
        language_instruction = LANGUAGE_INSTRUCTIONS.get(language, LANGUAGE_INSTRUCTIONS["ko"])
        
        prompt = f"""
{domain_prompt}

{language_instruction}

### ğŸ“‹ ë‹µë³€ ì‘ì„± ë‹¨ê³„ (ë°˜ë“œì‹œ ìˆœì„œëŒ€ë¡œ):

**STEP 1: ì§ˆë¬¸ í•µì‹¬ íŒŒì•…**
- ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” í•µì‹¬ ì •ë³´ê°€ ë¬´ì—‡ì¸ì§€ ëª…í™•íˆ íŒŒì•…
- ì˜ˆ: "ì¡¸ì—… í•™ì ì€?" â†’ ìˆ«ì(í•™ì ) ì°¾ê¸°, "í•„ìˆ˜ ê³¼ëª©ì€?" â†’ ê³¼ëª©ëª… ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°

**STEP 2: ì¸ë±ìŠ¤ì—ì„œ ì •í™•í•œ ì •ë³´ ê²€ìƒ‰**
- ì œê³µëœ ì¸ë±ìŠ¤ JSONì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì„¹ì…˜ ì°¾ê¸°
- page_ref, title, summary í•„ë“œë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•œ ìœ„ì¹˜ íŠ¹ì •

**STEP 3: í•µì‹¬ ë‹µë³€ ë¨¼ì € ì‘ì„± (1-2ë¬¸ì¥)**
- ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì„ ë¨¼ì € ëª…í™•í•˜ê²Œ ì œì‹œ
- ë°˜ë“œì‹œ í˜ì´ì§€ ì°¸ì¡° í¬í•¨: [ë¬¸ì„œëª…, p.í˜ì´ì§€]
- ì˜ˆ: "ì¡¸ì—… í•™ì ì€ 130í•™ì ì…ë‹ˆë‹¤ [ì¸ê³µì§€ëŠ¥ë°˜ë„ì²´, p.2]."

**STEP 4: ìƒì„¸ ì„¤ëª… ì¶”ê°€ (í•„ìš”ì‹œ)**
- í•µì‹¬ ë‹µë³€ ì´í›„ ì¶”ê°€ ë§¥ë½ì´ë‚˜ ìƒì„¸ ì •ë³´ ì œê³µ
- ëª¨ë“  ë¬¸ì¥ì— í˜ì´ì§€ ì°¸ì¡° í¬í•¨

**STEP 5: ì°¸ì¡° í˜ì´ì§€ ìš”ì•½**
- ë‹µë³€ ë§ˆì§€ë§‰ì— ğŸ“š **ì°¸ì¡° í˜ì´ì§€** í˜•ì‹ìœ¼ë¡œ ëª¨ë“  ì¶œì²˜ ë‚˜ì—´

### âš ï¸ ì¤‘ìš” ê·œì¹™:

1. **ì¸ë±ìŠ¤ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”** - "ì¸ë±ìŠ¤ì— í•´ë‹¹ ì •ë³´ê°€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€
2. **í˜ì´ì§€ ë²ˆí˜¸ í•„ìˆ˜** - ëª¨ë“  ì‚¬ì‹¤ì  ì§„ìˆ ì— [ë¬¸ì„œëª…, p.ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ í‘œê¸°
3. **ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ** - ì§ˆë¬¸ì— ì§ì ‘ ë‹µí•˜ëŠ” ì •ë³´ë¥¼ ìš°ì„  ì œì‹œ
4. **ìˆ«ì/ì´ë¦„ì€ ì •í™•íˆ** - í•™ì  ìˆ˜, ê³¼ëª©ëª…, ë‚ ì§œ ë“±ì€ ì¸ë±ìŠ¤ì— ìˆëŠ” ê·¸ëŒ€ë¡œ ê¸°ì¬
{comparison_prompt}

### ë‹µë³€ í…œí”Œë¦¿:

[í•µì‹¬ ë‹µë³€ 1-2ë¬¸ì¥ + í˜ì´ì§€ ì°¸ì¡°]

[ìƒì„¸ ì„¤ëª… (í•„ìš”ì‹œ) + í˜ì´ì§€ ì°¸ì¡°]
{f"\n[ë¬¸ì„œ ë¹„êµ ë¶„ì„: ê³µí†µì /ì°¨ì´ì  í‘œ]" if is_multi_doc else ""}

ğŸ“š **ì°¸ì¡° í˜ì´ì§€**: [ë¬¸ì„œëª…, p.X], [ë¬¸ì„œëª…, p.Y-Z]

### ì»¨í…ìŠ¤íŠ¸:
{context_str}

### ì§ˆë¬¸:
{user_question}

### ë‹µë³€ (ìœ„ ê·œì¹™ì„ ì² ì €íˆ ë”°ë¼ ì‘ì„±):
"""

        try:
            response = Config.CLIENT.models.generate_content(
                model=Config.MODEL_NAME,
                contents=prompt
            )
            if not response.text:
                raise ValueError("Empty response from model")
            
            if resolved_refs:
                traversal_info["resolved_references"] = [
                    {
                        "title": ref.get("title", ""),
                        "page_ref": ref.get("page_ref"),
                        "summary": ref.get("summary")
                    }
                    for ref in resolved_refs
                ]
            
            detector = create_detector(confidence_threshold=0.6)
            
            source_nodes = []
            if self.use_deep_traversal:
                for tree_idx, tree in enumerate(self.index_trees):
                    doc_name = self.index_filenames[tree_idx].replace("_index.json", "")
                    navigator = TreeNavigator(tree, doc_name)
                    relevant_nodes, _ = navigator.search(
                        query=user_question,
                        max_depth=max_depth,
                        max_branches=max_branches
                    )
                    source_nodes.extend([node["node"] for node in relevant_nodes])
            else:
                for tree in self.index_trees:
                    source_nodes.extend(self._extract_all_nodes(tree))
            
            if resolved_refs:
                source_nodes.extend(resolved_refs)
            
            detection_result = detector.detect(response.text, source_nodes)
            
            traversal_info["hallucination_detection"] = {
                "overall_confidence": detection_result["overall_confidence"],
                "is_reliable": detection_result["is_reliable"],
                "hallucinated_count": detection_result["hallucinated_count"],
                "total_sentences": detection_result["total_sentences"]
            }
            
            if detection_result["is_reliable"]:
                print(f"âœ… Hallucination check: {detection_result['overall_confidence']:.1%} confidence")
            else:
                print(f"âš ï¸ Hallucination detected: {detection_result['hallucinated_count']}/{detection_result['total_sentences']} sentences low confidence")
            

            cache = get_cache()
            cache_data = {
                "answer": response.text,
                "metadata": traversal_info
            }
            cache.set(
                question=user_question,
                index_files=self.index_filenames,
                use_deep_traversal=self.use_deep_traversal,
                max_depth=max_depth,
                max_branches=max_branches,
                domain_template=domain_template,
                language=language,
                response=cache_data,
                node_context=node_context
            )
            print(f"ğŸ’¾ Response cached")
            
            return response.text, traversal_info
        except Exception as e:
            print(f"âŒ Query failed: {e}")
            raise
    
    def _build_context_with_traversal(self, query: str, max_depth: int, max_branches: int) -> tuple[str, dict]:
        all_results = []
        all_visited = []
        all_selected = []
        
        for idx, tree in enumerate(self.index_trees):
            doc_name = self.index_filenames[idx].replace("_index.json", "")
            
            # ì•Œê³ ë¦¬ì¦˜ì— ë”°ë¼ ë‹¤ë¥¸ Navigator ì‚¬ìš©
            if self.traversal_algorithm == "beam_search":
                print(f"ğŸ” Using Beam Search (width={self.beam_width})")
                navigator = BeamSearchNavigator(tree, doc_name, beam_width=self.beam_width)
                relevant_nodes, trav_stats = navigator.search(
                    query=query,
                    max_depth=max_depth,
                    min_score_threshold=0.3
                )
                formatted = format_beam_results(relevant_nodes, doc_name)
            else:
                print(f"ğŸ” Using DFS (branches={max_branches})")
                navigator = TreeNavigator(tree, doc_name)
                relevant_nodes, trav_stats = navigator.search(
                    query=query,
                    max_depth=max_depth,
                    max_branches=max_branches
                )
                formatted = format_traversal_results(relevant_nodes, doc_name)
            
            all_results.append(formatted)
            
            # ì•Œê³ ë¦¬ì¦˜ì— ë”°ë¼ ë‹¤ë¥¸ í†µê³„ í˜•ì‹ ì²˜ë¦¬
            if self.traversal_algorithm == "beam_search":
                # Beam Search: nodes_visitedëŠ” ID ëª©ë¡, nodes_selectedëŠ” ì ìˆ˜ í¬í•¨
                all_visited.extend([f"{doc_name}: node_{i}" for i in range(trav_stats.get("nodes_visited", 0) if isinstance(trav_stats.get("nodes_visited"), int) else len(trav_stats.get("nodes_visited", [])))])
                all_selected.extend([{
                    "document": doc_name,
                    "title": node["node"].get("title", "Untitled"),
                    "page_ref": node["node"].get("page_ref", "N/A"),
                    "score": node.get("score", 0.0)
                } for node in relevant_nodes])
            else:
                # DFS: visited_titles ëª©ë¡
                all_visited.extend([f"{doc_name}: {title}" for title in trav_stats.get("visited_titles", [])])
                all_selected.extend([{
                    "document": doc_name,
                    "title": node["node"].get("title", "Untitled"),
                    "page_ref": node["node"].get("page_ref", "N/A")
                } for node in relevant_nodes])
        
        traversal_data = {
            "algorithm": self.traversal_algorithm,
            "beam_width": self.beam_width if self.traversal_algorithm == "beam_search" else None,
            "nodes_visited": all_visited,
            "nodes_selected": all_selected
        }
        
        final_context = "\n\n---\n\n".join(all_results)
        
        if self.enable_compression and self.compressor and all_selected:
            print(f"ğŸ—œï¸ Applying contextual compression ({len(all_selected)} nodes)")
            compression_result = self.compressor.compress(all_selected, query)
            
            if compression_result.compressed_count < compression_result.original_count:
                final_context = format_compressed_context(compression_result)
                traversal_data["compression"] = {
                    "original_count": compression_result.original_count,
                    "compressed_count": compression_result.compressed_count,
                    "ratio": compression_result.compression_ratio,
                    "tokens_saved": compression_result.total_tokens_saved
                }
                print(f"   Compressed: {compression_result.original_count} â†’ {compression_result.compressed_count} nodes")
                print(f"   Tokens saved: ~{compression_result.total_tokens_saved}")
        
        return final_context, traversal_data
    
    def _build_flat_context(self) -> str:
        combined_context = []
        for idx, tree in enumerate(self.index_trees):
            doc_name = self.index_filenames[idx].replace("_index.json", "")
            combined_context.append({
                "document": doc_name,
                "content": tree
            })
        
        return json.dumps(combined_context, ensure_ascii=False)
    
    def _extract_all_nodes(self, tree: Dict[str, Any]) -> List[Dict[str, Any]]:
        nodes = []
        
        def traverse(node):
            if isinstance(node, dict):
                nodes.append(node)
                if "children" in node and isinstance(node["children"], list):
                    for child in node["children"]:
                        traverse(child)
        
        traverse(tree)
        return nodes